{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 12500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08,
      "grad_norm": 1.1949331760406494,
      "learning_rate": 2.92016e-05,
      "loss": 3.6326,
      "step": 500
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.9872227311134338,
      "learning_rate": 2.84016e-05,
      "loss": 1.6846,
      "step": 1000
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.932895302772522,
      "learning_rate": 2.76016e-05,
      "loss": 1.3113,
      "step": 1500
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.9922868013381958,
      "learning_rate": 2.68016e-05,
      "loss": 1.1221,
      "step": 2000
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.893165647983551,
      "learning_rate": 2.6001600000000002e-05,
      "loss": 0.9897,
      "step": 2500
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.0522221326828003,
      "learning_rate": 2.52016e-05,
      "loss": 0.8961,
      "step": 3000
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.131082534790039,
      "learning_rate": 2.44016e-05,
      "loss": 0.817,
      "step": 3500
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.0510787963867188,
      "learning_rate": 2.36016e-05,
      "loss": 0.7629,
      "step": 4000
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.8258661031723022,
      "learning_rate": 2.2801600000000002e-05,
      "loss": 0.7311,
      "step": 4500
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.7868399024009705,
      "learning_rate": 2.20016e-05,
      "loss": 0.7029,
      "step": 5000
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.89504075050354,
      "learning_rate": 2.12016e-05,
      "loss": 0.6844,
      "step": 5500
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.8991490006446838,
      "learning_rate": 2.0401599999999998e-05,
      "loss": 0.6687,
      "step": 6000
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.685794472694397,
      "learning_rate": 1.9601600000000002e-05,
      "loss": 0.6626,
      "step": 6500
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.0983366966247559,
      "learning_rate": 1.8801600000000003e-05,
      "loss": 0.6538,
      "step": 7000
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.5965956449508667,
      "learning_rate": 1.80016e-05,
      "loss": 0.645,
      "step": 7500
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.9366205334663391,
      "learning_rate": 1.72016e-05,
      "loss": 0.6371,
      "step": 8000
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.6584324240684509,
      "learning_rate": 1.64016e-05,
      "loss": 0.6344,
      "step": 8500
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.8314720988273621,
      "learning_rate": 1.56016e-05,
      "loss": 0.6285,
      "step": 9000
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.9097550511360168,
      "learning_rate": 1.4801599999999999e-05,
      "loss": 0.6277,
      "step": 9500
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.7694911360740662,
      "learning_rate": 1.4001600000000002e-05,
      "loss": 0.6254,
      "step": 10000
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.9431028366088867,
      "learning_rate": 1.32016e-05,
      "loss": 0.6215,
      "step": 10500
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.5686841011047363,
      "learning_rate": 1.24016e-05,
      "loss": 0.6162,
      "step": 11000
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 1.7234430313110352,
      "learning_rate": 1.1601600000000001e-05,
      "loss": 0.6183,
      "step": 11500
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.46298760175704956,
      "learning_rate": 1.08016e-05,
      "loss": 0.6161,
      "step": 12000
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.5239625573158264,
      "learning_rate": 1.0001600000000001e-05,
      "loss": 0.6115,
      "step": 12500
    }
  ],
  "logging_steps": 500,
  "max_steps": 18750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2350055424000000.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
